- job_id: JR2011392
  job_title: AI Software Engineer, LLM Inference Performance Analysis - New College Grad 2026
  company_name: Nvidia
  location: United States
  status: processed
  posting_link: https://nvidia.wd5.myworkdayjobs.com/NVIDIAExternalCareerSite/job/US-CA-Santa-Clara/AI-Software-Engineer--LLM-Inference-Performance-Analysis---New-College-Grad-2026_JR2011392?source=jobboardlinkedin
  job_description: "NVIDIA is at the forefront of the generative AI revolution. We are looking for a Software Engineer, Performance Analysis, and Optimization for LLM Inference, to join our performance engineering team. In this role, you will focus on improving the efficiency and scalability of large language model (LLM) inference on NVIDIA Computing Platforms through compiler and kernel-level analysis and optimizations. You will work on key components that span IR-based compiler optimization, graph-level transformations, and precompiled kernel performance tuning to deliver innovative inference speed and efficiency.\n\nAs a core contributor, you will collaborate with groups passionate about compiler, kernel, hardware, and framework development. You will analyze performance bottlenecks, develop new optimization passes, and validate gains through profiling and projection tools. Your work will directly influence the runtime behavior and hardware utilization of next-generation LLMs deployed across NVIDIA’s data center and embedded platforms.\n\nWhat you'll be doing:\n\nAnalyze the performance of LLMs running on NVIDIA Compute Platforms using profiling, benchmarking, and performance analysis tools.\n\nUnderstand and find opportunities for compiler optimization pipelines, including IR-based compiler middle-end optimizations and kernel-level transformation s\n\nDesign and develop new compiler passes and optimizations techniques to deliver best-in-class, robust, and maintainable compiler infrastructure and tools.\n\nCollaborate with hardware architecture, compiler, and kernel teams to understand how firmware and circuitry co-design enables efficient LLM inference.\n\nWork with globally distributed teams across compiler, kernel, hardware, and framework domains to investigate performance issues and contribute to solutions.\n\nWhat we need to see:\n\nMaster’s or PhD in Computer Science, Computer Engineering, or a related field, or equivalent experience.\n\nStrong hands-on programming expertise in C++ and Python, with solid software engineering fundamentals.\n\nFoundational understanding of modern deep learning models (including transformers and LLMs) and interest in inference performance and optimization.\n\nExposure to compiler concepts such as intermediate representations (IR), graph transformations, scheduling, or code generation through coursework, research, internships, or projects.\n\nFamiliarity with at least one deep learning framework or compiler/runtime ecosystem (e.g., TensorRT-LLM, PyTorch, JAX/XLA, Triton, vLLM, or similar).\n\nAbility to analyze performance bottlenecks and reason about optimization opportunities across model execution, kernels, and runtime systems.\n\nExperience working on class projects, internships, research, or open-source contributions involving performance-critical systems, compilers, or ML infrastructure.\n\nStrong communication skills and the ability to collaborate effectively in a fast-paced, team-oriented environment.\n\nWays to stand out from the crowd:\n\nProficiency in CUDA programming and familiarity with GPU-accelerated deep learning frameworks and performance tuning techniques.\n\nShowcase innovative applications of agentic AI tools that enhance productivity and workflow automation.\n\nActive engagement with the open-source LLVM or MLIR community to ensure tighter integration and alignment with upstream efforts.\n\nNVIDIA is recognized as one of the world’s most desirable engineering environments, built by teams who value technical depth, innovation, and impact. We work alongside some of the best minds in GPU computing, systems software, and AI. If you’re driven by performance, enjoy solving sophisticated problems, and thrive in an environment that rewards initiative and technical perfection, we’d love to hear from you!\n\nYour base salary will be determined based on your location, experience, and the pay of employees in similar positions. The base salary range is 124,000 USD - 195,500 USD for Level 2, and 152,000 USD - 218,500 USD for Level 3.\nYou will also be eligible for equity and benefits.\n\nApplications for this job will be accepted at least until January 18, 2026.\nThis posting is for an existing vacancy. \n\nNVIDIA uses AI tools in its recruiting processes.\n\nNVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.\n"
- job_id: 6df58d3e-855a-423e-99fd-a56ac8824b34
  job_title: AI Engineer New Grad 2025-2026 - Poe (Remote)
  company_name: Quora
  location: United States
  status: processed
  posting_link: https://jobs.ashbyhq.com/quora/6df58d3e-855a-423e-99fd-a56ac8824b34?gh_src=fa1aa7222
  job_description: |-
    AI Engineer New Grad 2025-2026 - Poe (Remote)
    Location
    Remote - Multiple Locations, United States, Canada

    Employment Type
    Full time

    Location Type
    Remote

    Department
    Engineering

    Overview
    Application
    [Quora is a privately held, "remote-first" company. This position can be performed remotely from multiple countries around the world. Please visit careers.quora.com/eligible-countries for details regarding employment eligibility by country.]

    About Quora:
    Quora’s mission is to grow the world's collective intelligence. To do so, we have two platforms:

    Quora: a global knowledge sharing platform with over 300M monthly unique visitors, bringing people together to share insights on various topics and providing a unique platform to learn and connect with others.

    Poe: a platform providing millions of global users with one place to chat, explore and build with a wide variety of AI language models (bots), including GPT-5, Claude Sonnet 4.5, Grok 4, Veo 3.1, Gemini 2.5 Flash Image (Nano Banana), and more. As AI capabilities rapidly advance, Poe provides a single platform to instantly integrate and utilize these new models.

    Behind these products are passionate, collaborative, and high-performing global teams. We have a culture rooted in transparency, idea-sharing, and experimentation that allows us to celebrate success and grow together through meaningful work. Join us on this journey to create a positive impact and make a significant change in the world.

    This role will be working on our Poe product.

    About the Team and Role:
    Our small engineering team works on challenging problems every day. We have a culture that's rooted in constantly learning and improving, and our engineers are encouraged to think big and experiment with new ideas. Using continuous deployment, we quickly see our changes in the product and make fast iterations. Everyone on the engineering team has a huge impact on our product and our company.

    At Poe, we use AI in various parts of the product - bot/app routing and recommendation, agent flow, RAG, etc. Our team of AI Engineers has high impact by advancing the current AI systems, building performant and reliable LLM applications, and collaborating with our product team to uncover new opportunities for the Poe product. You will also play a key role in developing tools and abstractions that other developers will build on top of.

    Responsibilities:
    Work with other engineers on a wide variety of AI engineering tasks, including prompt engineering, retrieval-augmented generation, and agentic workflow optimization, etc to improve our existing applied AI systems

    Identify new opportunities to apply emerging AI capabilities to different parts of the Poe product

    Take end-to-end ownership of applied AI systems - from prototyping, data pipelines, model optimization/evaluation to reliable deployment at scale

    Minimum Requirements:
    Ability to be available for meetings and impromptu communication during Quora's “coordination hours" (Mon-Fri: 9am-3pm Pacific Time)

    A 2025 or Summer 2026 graduate with or pursuing a B.S., M.S., or Ph.D. in Computer Science, Engineering or a related technical field

    Strong engineering background (Python or TypeScript)

    Understanding of mathematical foundations of Machine Learning algorithms

    Experience of LLM applications or transformer models

    A passion for learning and always improving yourself and the team around you

    Preferred Requirements:
    Previous software engineering experience via an internship, work experience or coding competition

    Previous hands-on experience working on LLM and prompt engineering

    Passion for Poe and Quora’s mission and goals

    At Quora, we value diversity and inclusivity and welcome individuals from all backgrounds, including marginalized or underrepresented groups in tech, to apply for our job openings. We encourage all candidates who share a passion for growing the world’s knowledge, even those who may not strictly meet all the preferred requirements, to apply, as we know that a diverse range of perspectives can have a significant impact on our products and our culture.

    Additional Information:
    We are accepting applications on an ongoing basis. This role is a backfill for an existing vacancy.

    Quora offers a wide range of benefits including medical/dental/vision coverage, equity refreshers, remote work reimbursement, paid time off, employee assistance programs, and more. Benefits are country-specific and may vary. For more information on benefits, visit this link: https://www.careers.quora.com/benefits

    There are many factors that will determine the starting pay, including but not limited to experience, location, education, and business needs.

    US candidates only: For US based applicants, the salary range is $107,360 - $152,900 USD + equity + benefits.

    Canada candidates only: For Toronto and Vancouver based applicants, the salary range is $140,796 - $160,415 CAD + equity + benefits. For all other locations in Canada, the salary range is $131,409 - $149,720 CAD + equity + benefits.

    We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

    AI technology may assist in sorting applications and recording interview notes, but all decisions are made by a member of our team.

    Job Applicant Privacy Notice: https://www.careers.quora.com/applicant-privacy-notice

    #LI-SS2
    #LI-REMOTE
